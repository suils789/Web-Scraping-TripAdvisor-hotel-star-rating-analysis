{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d8647373767a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[1;31m# Create datadir if does not exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import requests\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "base_url = \"http://www.tripadvisor.com\"\n",
    "user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.76 Safari/537.36\"\n",
    "\n",
    "\"\"\" STEP 1  \"\"\"\n",
    "def get_tourism_page(city, state):\n",
    "    \"\"\"\n",
    "        Return json containing the URL\n",
    "        of the tourism city page\n",
    "    \"\"\"\n",
    "\n",
    "    # EXAMPLE: http://www.tripadvisor.com/Boston\n",
    "\n",
    "    url = base_url+ \"/\"+ city\n",
    "    \n",
    "    log.info(\"URL \tTO REQUEST: %s \\n\" % url)\n",
    "    # Given the url, request the HTML page\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    html = response.text.encode('utf-8')\n",
    "   \n",
    "   # Save to file\n",
    "    with open(os.path.join(args.datadir, city + '-search-page.json'), \"w\") as h:\n",
    "        h.write(html)\n",
    "\n",
    "    soup = BeautifulSoup(html)\n",
    "    li = soup.find(\"link\", {\"hreflang\": \"en\"})\n",
    "    return li['href']\n",
    "\n",
    "\"\"\" STEP 2  \"\"\"\n",
    "def get_city_page(tourism_url):\n",
    "    \"\"\"\n",
    "        Get the URL of the hotels of the city\n",
    "        using the URL returned by the function\n",
    "        get_tourism_page()\n",
    "        \"\"\"\n",
    "\n",
    "    url = tourism_url\n",
    "\n",
    "    # Given the url, request the HTML page\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(url, headers=headers)\n",
    "   \n",
    "    html = response.text.encode('utf-8')\n",
    "\t\n",
    "    # Save to file\n",
    "    with open(os.path.join(args.datadir, args.city + '-tourism-page.html'), \"w\") as h:\n",
    "        h.write(html)\n",
    "\n",
    "\n",
    "    # Use BeautifulSoup to extract the url for the list of hotels in\n",
    "    # the city and state we are interested in.\n",
    "    # For exampel in this case we need to\n",
    "    #<li class=\"hotels twoLines\">\n",
    "    #<a href=\"/Hotels-g60745-Boston_Massachusetts-Hotels.html\" data-trk=\"hotels_nav\"\n",
    "    soup = BeautifulSoup(html)\n",
    "\n",
    "    li = soup.find(\"li\", {\"class\": \"hotels twoLines\"})\n",
    "    city_url = li.find('a', href = True)\n",
    "    log.info(\"CITY PAGE URL: %s\" % city_url['href'])\n",
    "\n",
    "    return city_url['href']\n",
    "\n",
    "\n",
    "\"\"\" STEP 3 \"\"\"\n",
    "def get_hotellist_page(city_url, count):\n",
    "\t\"\"\" Get the hotel list page given the url returned by\n",
    "\t\tget_city_page(). Return the html after saving\n",
    "\t\tit to the datadir \n",
    "\t\"\"\"\n",
    "\n",
    "\turl = base_url + city_url\n",
    "\t# Sleep 2 sec before starting a new http request\n",
    "\ttime.sleep(2)\n",
    "\t# Request page\n",
    "\theaders = { 'User-Agent' : user_agent }\n",
    "\tresponse = requests.get(url, headers=headers)\n",
    "\thtml = response.text.encode('utf-8')\n",
    "\t# Save the \n",
    "\twith open(os.path.join(args.datadir, args.city + '-hotelist-' + str(count) + '.html'), \"w\") as h:\n",
    "\t \th.write(html)\n",
    "\treturn html\n",
    "\t\n",
    "\n",
    "\"\"\" STEP 4 \"\"\"\n",
    "def parse_hotellist_page(html):\n",
    "    \"\"\" Parse the html pages returned by get_hotellist_page().\n",
    "        Return the next url page to scrape (a city can have\n",
    "        more than one page of hotels) if there is, else exit\n",
    "        the script.\n",
    "    \"\"\"\n",
    "\n",
    "    soup = BeautifulSoup(html)\n",
    "    # Extract hotel name, star rating and number of reviews\n",
    "    hotel_boxes = soup.findAll('div', {'class' :'listing easyClear  p13n_imperfect '})\n",
    "   \n",
    "    for hotel_box in hotel_boxes:\n",
    "        name = hotel_box.find('div', {'class' :'listing_title'}).find(text=True)\n",
    "        \n",
    "        try:\n",
    "            rating = hotel_box.find('div', {'class' :'listing_rating'})\n",
    "        \n",
    "            reviews = rating.find('span', {'class' :'more review_count'}).find(text=True)\n",
    "            \n",
    "            stars = hotel_box.find(\"img\", {\"class\" : \"sprite-ratings\"})\n",
    "            \n",
    "        except:\n",
    "            log.error(\"No ratings for this hotel\")\n",
    "            reviews = \"N/A\"\n",
    "            stars = 'N/A'\n",
    "\n",
    "        if stars != 'N/A':\n",
    "            #log.info(\"Stars: %s\" % stars['alt'].split()[0])\n",
    "            stars = stars['alt'].split()[0]\n",
    "        log.info(\"HOTEL NAME: %s\" % name)\n",
    "        log.info(\"HOTEL REVIEWS: %s\" % reviews)\n",
    "        log.info(\"HOTEL STAR RATING: %s \\n\" % stars)\n",
    "\n",
    "    # Get next URL page if exists, else exit\n",
    "    div = soup.find(\"div\", {\"class\" : \"unified pagination standard_pagination\"})\n",
    "    # check if last page\n",
    "    if div.find('span', {'class' : 'nav next ui_button disabled'}):\n",
    "        log.info(\"We reached last page\")\n",
    "        sys.exit()\n",
    "    # If it is not las page there must be the Next URL\n",
    "    hrefs = div.findAll('a', href= True)\n",
    "    for href in hrefs:\n",
    "        if href.find(text = True) == 'Next':\n",
    "            log.info(\"Next url is %s\" % href['href'])\n",
    "            return href['href']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Get current directory\n",
    "    current_dir = os.getcwd()\n",
    "\n",
    "    # Create datadir if does not exist\n",
    "    if not os.path.exists(os.path.join(current_dir, args.datadir)):\n",
    "        os.makedirs(os.path.join(current_dir, args.datadir))\n",
    "    \n",
    "    # Obtain the url of the toursim page \n",
    "    tourism_url = get_tourism_page(args.city, args.state)\n",
    "    #Get URL to obtaint the list of hotels in a specific city\n",
    "    city_url = get_city_page(tourism_url)\n",
    "    c=0\n",
    "    while(True):\n",
    "        c +=1\n",
    "        html = get_hotellist_page(city_url,c)\n",
    "        city_url = parse_hotellist_page(html)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
